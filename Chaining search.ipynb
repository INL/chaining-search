{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaining search\n",
    "\n",
    "\n",
    "\n",
    "## Sphinx documentatie: https://pythonhosted.org/an_example_pypi_project/sphinx.html\n",
    "## in voorbeelden handige python functies opnemen\n",
    "## zoals ; .sort_values(ascending=False,by=['raw_freq']));  list enz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the cell below to show the UI, and fill in your search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T15:21:20.739836Z",
     "start_time": "2019-02-26T15:21:20.701235Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.ui.search import create_corpus_ui\n",
    "\n",
    "# Create corpus UI, creates references to field contents\n",
    "corpusQueryField, corpusField = create_corpus_ui()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Click the cell below and press Run to perform the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T15:21:31.813025Z",
     "start_time": "2019-02-26T15:21:29.718607Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "#from chaininglib import search\n",
    "query= corpusQueryField.value\n",
    "corpus_name = corpusField.value\n",
    "df_corpus = create_corpus(corpus_name).pattern(query).search().kwic()\n",
    "#df_corpus = load_dataframe('mijn_resultaten.csv')\n",
    "display_df(df_corpus, labels=\"Results\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the cell below to show the UI, and fill in your search query in the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:14:00.448490Z",
     "start_time": "2019-02-26T13:14:00.197799Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from chaininglib.ui.search import create_lexicon_ui\n",
    "\n",
    "#from chaininglib import ui\n",
    "searchWordField, lexiconField = create_lexicon_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Click the cell below and press Run to perform the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:14:01.931797Z",
     "start_time": "2019-02-26T13:14:01.382671Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.LexiconQuery import *\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "search_word = searchWordField.value\n",
    "lexicon_name = lexiconField.value\n",
    "# USER: can replace this by own custom query\n",
    "lex = create_lexicon(lexicon_name).lemma(search_word).search()\n",
    "df_lexicon = lex.kwic()\n",
    "display_df(df_lexicon)\n",
    "#df_columns_list = list(df_lexicon.columns.values)\n",
    "#df_lexicon_in_columns = df_lexicon[df_columns_list]\n",
    "#display(df_lexicon_in_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 1 (parallel): Frequency of *puur*+verb and *zuiver*+verb compared\n",
    "* Below cell searches for *puur*+verb and for *zuiver*+verb in the CHN corpus\n",
    "* Compare frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T15:21:53.003186Z",
     "start_time": "2019-02-26T15:21:46.281694Z"
    }
   },
   "outputs": [],
   "source": [
    "#from chaininglib import search\n",
    "from IPython.core.display import display, HTML\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.ui.dfui import display_df\n",
    "from chaininglib.utils.dfops import column_difference\n",
    "\n",
    "# Word 1: puur\n",
    "word1= \"puur\"\n",
    "cq1 = create_corpus(\"chn\").pattern(r'[word=\"' + word1 + r'\"][pos=\"VRB.*\"]')\n",
    "df_corpus1 = cq1.search().kwic()\n",
    "display_df(df_corpus1, word1)\n",
    "\n",
    "# Word 2: zuiver\n",
    "word2 = \"zuiver\"\n",
    "cq2 = create_corpus(\"chn\").pattern(r'[word=\"' + word2 + r'\"][pos=\"VRB.*\"]')\n",
    "df_corpus2 = cq2.search().kwic()\n",
    "display_df(df_corpus2, word2)\n",
    "\n",
    "# Compute difference\n",
    "diff_left, diff_right, intersec = column_difference(df_corpus1[\"word 1\"], df_corpus2[\"word 1\"])\n",
    "# Elements of 1 that are not in 2\n",
    "display(HTML('Werkwoorden voor <b>' + word1 + '</b> niet in <b>' + word2 + '</b>: ' + \", \".join(diff_left)))\n",
    "# Elements of 2 that are not in 1\n",
    "display(HTML('Werkwoorden voor <b>' + word2 + '</b> niet in <b>' + word1 + '</b>: ' + \", \".join(diff_right)))\n",
    "# Elements both in 1 and 2\n",
    "display(HTML('Werkwoorden zowel voor <b>' + word1 + '</b> als voor <b>' + word2 + '</b>: ' + \", \".join(intersec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 2 (sequential): Retrieve synonyms from DiaMaNT, look up in Gysseling\n",
    "* Below cell searches for term \"boek\" in DiaMaNT, and looks up all variants in Gysseling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:41:57.928250Z",
     "start_time": "2019-02-26T13:41:51.125673Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.LexiconQuery import *\n",
    "from IPython.core.display import display, HTML\n",
    "from chaininglib.search.corpusQueries import corpus_query\n",
    "from chaininglib.process.lexicon import get_diamant_synonyms\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "search_word = \"boek\"\n",
    "lexicon_name = \"diamant\"\n",
    "corpus= \"gysseling\"\n",
    "\n",
    "# First, lookup synonyms in DiaMaNT\n",
    "lq = create_lexicon(lexicon_name).lemma(search_word).search()\n",
    "df_lexicon = lq.kwic()\n",
    "syns = get_diamant_synonyms(df_lexicon)\n",
    "syns.add(search_word) # Also add search word itself\n",
    "display(HTML('Synoniemen voor <b>' + search_word + '</b>: ' + \", \".join(syns)))\n",
    "\n",
    "# Search for all synonyms in corpus\n",
    "## Create queries: search by lemma\n",
    "syns_queries = [corpus_query(lemma=syn) for syn in syns]\n",
    "## Search for all synonyms in corpus\n",
    "cq = create_corpus(corpus).pattern(syns_queries)\n",
    "df = cq.search().kwic()\n",
    "display_df(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 3: Build a frequency list of the lemma of some corpus output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-26T13:03:10.724Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.process.corpus import *\n",
    "from chaininglib.ui.dfui import *\n",
    "\n",
    "# do some corpus search\n",
    "\n",
    "corpus_to_search=\"chn\"\n",
    "df_corpus = create_corpus(corpus_to_search).detailed_context(True).pos(\"NOUN\").search().kwic()\n",
    "display_df(df_corpus)\n",
    "\n",
    "# compute and display a table of the frequencies of the lemmata\n",
    "\n",
    "freq_df = get_frequency_list(df_corpus)\n",
    "display_df(freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T15:46:20.519833Z",
     "start_time": "2019-01-16T15:46:20.516208Z"
    }
   },
   "source": [
    "## Case study (sequential) 4: Find occurences of attributive adjectives not ending with -e, even though they are preceeded by a definite article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:42:36.250370Z",
     "start_time": "2019-02-26T13:42:19.040009Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.LexiconQuery import *\n",
    "from chaininglib.utils.dfops import df_filter\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "corpus_to_search=\"opensonar\"\n",
    "lexicon_to_search=\"molex\"\n",
    "\n",
    "# CORPUS: get [article + attributive adjective + nouns] combinations in which the adjective does not end with -e\n",
    "print('Get occurences of attributive adjectives not ending with -e')\n",
    "cq = create_corpus(corpus_to_search).pattern(r'[lemma=\"de|het\"][word=\"^g(.+)[^e]$\" & pos=\"ADJ\"][pos=\"NOUN\"]')\n",
    "df_corpus = cq.search().kwic()\n",
    "\n",
    "# LEXICON: get adjectives the lemma of which does not end with -e\n",
    "lq = create_lexicon(lexicon_to_search).lemma('^g(.+)[^e]$').pos('ADJ').search()\n",
    "df_lexicon = lq.search().kwic()\n",
    "\n",
    "# LEXICON: get adjectives having a final -e in definite attributive use\n",
    "print('Filtering lexicon results')\n",
    "final_e_condition = df_filter(df_lexicon[\"wordform\"], 'e$')\n",
    "df_lexicon_form_e = df_lexicon[ final_e_condition ]\n",
    "\n",
    "# RESULT: get the records out of our first list in which the -e-less-adjectives match the lemma form of our last list\n",
    "print('List of attributive adjectives not ending with -e even though they should have a final -e:')\n",
    "e_forms = list(df_lexicon_form_e.lemma)\n",
    "no_final_e_condition = df_filter(df_corpus[\"word 1\"], query=set(e_forms), method=\"isin\")\n",
    "result_df = df_corpus[ no_final_e_condition ]\n",
    "display_df( result_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study (sequential) 5: (morphosyntactic lexicon and possibly unannotated corpus) Look up inflected forms and spelling variants for a given lemma in a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:46:02.271245Z",
     "start_time": "2019-02-26T13:42:39.514812Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.ui.dfui import display_df\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.LexiconQuery import *\n",
    "\n",
    "lexicon_to_search=\"molex\"\n",
    "corpus_to_search=\"chn\"\n",
    "\n",
    "##############################################\n",
    "# TODO  zelfde met meerdere lemmata en gegroepeerd \n",
    "##############################################\n",
    "\n",
    "lemma_to_look_for=\"denken\"\n",
    "\n",
    "# LEXICON: Search for the inflected forms of a lemma in a morphosyntactic lexicon\n",
    "lq = create_lexicon(lexicon_to_search).lemma(lemma_to_look_for).search()\n",
    "df_lexicon = lq.kwic()\n",
    "display_df(df_lexicon)\n",
    "\n",
    "# Put all inflected forms into a list\n",
    "inflected_wordforms = list(df_lexicon.wordform)\n",
    "\n",
    "# CORPUS: Look up the inflected forms in a (possibly unannotated) corpus\n",
    "# beware: If the corpus is not annotated, all we can do is searching for the inflected words\n",
    "#         But if the corpus is lemmatized, we have to make sure we're retrieving correct data by specifying the lemma as well\n",
    "annotated_corpus = True\n",
    "query = r'[lemma=\"'+lemma_to_look_for+r'\" & word=\"'+r\"|\".join(inflected_wordforms)+r'\"]' if annotated_corpus else r'[word=\"'+r\"|\".join(inflected_wordforms)+r'\"]'\n",
    "cq = create_corpus(corpus_to_search).pattern(query).search()\n",
    "df_corpus = cq.kwic() \n",
    "display_df(df_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 6:\n",
    "## Build a function with which we can gather all lemmata \n",
    "## of a lexicon with a given part-of-speech,\n",
    "## and use that function to build a frequecy list of those lemmata in a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:47:30.286814Z",
     "start_time": "2019-02-26T13:46:04.391343Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.LexiconQuery import *\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.process.corpus import get_frequency_list\n",
    "from chaininglib.ui.dfui import display_df\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# build a function as required. We will run it afterwards\n",
    "\n",
    "def get_frequency_list_given_a_corpus(lexicon, pos, corpus):\n",
    "    \n",
    "    # LEXICON: get a lemmata list to work with\n",
    "\n",
    "    # query the lexicon\n",
    "    lq = create_lexicon(lexicon).pos(pos).search()\n",
    "    df_lexicon = lq.kwic()\n",
    "\n",
    "    # Put the results into an array, so we can loop through the found lemmata\n",
    "    lexicon_lemmata_arr = [w.lower() for w in df_lexicon[\"writtenForm\"]]\n",
    "\n",
    "    # Instantiate a DataFrame, in which we will gather all single lemmata occurences\n",
    "    df_full_list = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # CORPUS: loop through the lemmata list, query the corpus with each lemma, and count the results\n",
    "\n",
    "    # It's a good idea to query more than one lemma at at the time,\n",
    "    # but not too many, otherwise the server will get overloaded!\n",
    "    nr_of_lemmata_to_query_atonce = 100\n",
    "\n",
    "    # loop over lemmata list \n",
    "    for i in range(0, len(lexicon_lemmata_arr), nr_of_lemmata_to_query_atonce):\n",
    "        \n",
    "        # slice to small array of lemmata to query at once\n",
    "        small_lemmata_arr = lexicon_lemmata_arr[i : i+nr_of_lemmata_to_query_atonce] \n",
    "\n",
    "        # join set of lemmata to send them in a query all at once\n",
    "        # beware: single quotes need escaping\n",
    "        lemmata_list = \"|\".join(small_lemmata_arr).replace(\"'\", \"\\\\\\\\'\")\n",
    "        cq = create_corpus(corpus).pattern(r'[lemma=\"' + lemmata_list + r'\"]').search()\n",
    "        df_corpus = cq.kwic()\n",
    "\n",
    "        # add the results to the full list\n",
    "        df_full_list = pd.concat( [df_full_list, df_corpus[\"lemma 0\"]] )     \n",
    "        \n",
    "\n",
    "    # make sure the columnswith contains the lemmata is called 'lemma', as it is required by the get_frequency_list function\n",
    "    df_full_list.columns = ['lemma']\n",
    "\n",
    "    # we're done with querying, build the frequency list now\n",
    "    freq_df = get_frequency_list(df_full_list)\n",
    "\n",
    "    return freq_df\n",
    "\n",
    "    \n",
    "# run it!\n",
    "\n",
    "lexicon=\"molex\"\n",
    "corpus_to_search=\"chn\"\n",
    "pos=\"CONJ\"\n",
    "\n",
    "freq_df = get_frequency_list_given_a_corpus(lexicon, pos, corpus_to_search)\n",
    "\n",
    "display_df(freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 7: Build a frequency table of some corpus, based on lemma list of a given lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:47:56.038959Z",
     "start_time": "2019-02-26T13:47:34.501907Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.utils.dfops import get_rank_diff\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "# For this case study, we need to run the previous case study first, because it generates a function we need here\n",
    "\n",
    "base_lexicon=\"molex\"\n",
    "corpus_to_search1=\"opensonar\"\n",
    "corpus_to_search2=\"chn\"\n",
    "\n",
    "# build frequency tables of two corpora\n",
    "\n",
    "df_frequency_list1 = get_frequency_list_given_a_corpus(base_lexicon, \"NOUN\", corpus_to_search1)\n",
    "# sort and display\n",
    "df_top25_descending = df_frequency_list1.sort_values(ascending=False,by=['token count']).head(25)\n",
    "df_top25_ascending =  df_frequency_list1.sort_values(ascending=True, by=['rank']).head(25)\n",
    "display_df( df_top25_ascending )\n",
    "print(type(df_top25_descending['token count']))\n",
    "display_df( df_top25_descending['token count'], labels='chart df1', mode='chart' )\n",
    "\n",
    "df_frequency_list2 = get_frequency_list_given_a_corpus(base_lexicon, \"NOUN\", corpus_to_search2)\n",
    "# sort and display\n",
    "df_top25_descending = df_frequency_list2.sort_values(ascending=False,by=['token count']).head(25)\n",
    "df_top25_ascending =  df_frequency_list2.sort_values(ascending=True, by=['rank']).head(25)\n",
    "display_df( df_top25_ascending )\n",
    "display_df( df_top25_descending['token count'], labels='chart df2', mode='chart' )\n",
    "\n",
    "\n",
    "# TODO: lemmata tonen die in 1 of 2 ontbreken\n",
    "\n",
    "# compute the rank diff of lemmata in frequency tables\n",
    "\n",
    "# sort and display\n",
    "df_rankdiffs = get_rank_diff(df_frequency_list1, df_frequency_list2)\n",
    "\n",
    "display_df(df_rankdiffs.sort_values(by=['rank_diff']).head(25))\n",
    "\n",
    "df_top25_descending = df_rankdiffs.sort_values(ascending=False, by=['rank_diff']).head(25)\n",
    "display_df( df_top25_descending['rank_diff'], labels='chart large diff', mode='chart' )\n",
    "\n",
    "df_top25_ascending = df_rankdiffs.sort_values(ascending=True, by=['rank_diff']).head(25)\n",
    "display_df( df_top25_ascending['rank_diff'], labels='chart small diff', mode='chart' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 8: search in a corpus for wordforms of a lemma, which are not included in this lemma's paramadigm in a lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:50:47.228748Z",
     "start_time": "2019-02-26T13:48:45.777207Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.LexiconQuery import *\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "\n",
    "\n",
    "# Let's build a function to do the job:\n",
    "# The function will require a lexicon name and a part-of-speech to limit the search to, and the name of a corpus to be searched.\n",
    "# It will return a Pandas DataFrame associating lemmata to their paradigms ('known_wordforms' column) and\n",
    "# missing wordforms found in the corpus ('unknown_wordforms' column).\n",
    "\n",
    "def get_missing_wordforms(lexicon, pos, corpus):    \n",
    "    \n",
    "    print('Finding missing wordforms in a lexicon can take a long time...');\n",
    "    \n",
    "    # LEXICON: \n",
    "    # get a lemmata list having a given part-of-speech\n",
    "    \n",
    "    lq = create_lexicon(lexicon).pos(pos).search()\n",
    "    df_lexicon = lq.kwic()\n",
    "    \n",
    "    # Put the results into an array, so we can loop through the list of lemmata\n",
    "    lexicon_lemmata_arr = [w.lower() for w in df_lexicon[\"writtenForm\"]]\n",
    "    \n",
    "    # Prepare the output:\n",
    "    # instantiate a DataFrame for storing lemmata and mssing wordforms\n",
    "    df_enriched_lexicon = pd.DataFrame(index=lexicon_lemmata_arr, columns=['lemma', 'pos', 'known_wordforms', 'unknown_wordforms'])\n",
    "    df_enriched_lexicon.index.name = 'lemmata'\n",
    "    \n",
    "    # CORPUS: \n",
    "    # loop through the lemmata list, query the corpus for each lemma, \n",
    "    # and compute paradigms differences between both\n",
    "\n",
    "    \n",
    "    # loop through the lemmata list\n",
    "    # and query the corpus for occurances of the lemmata\n",
    "    \n",
    "    # It's a good idea to work with more than one lemma at the time (speed)!\n",
    "    nr_of_lemmata_to_query_atonce = 100\n",
    "    \n",
    "    for i in range(0, len(lexicon_lemmata_arr), nr_of_lemmata_to_query_atonce):\n",
    "        \n",
    "        # slice to small array of lemmata to query at once\n",
    "        small_lemmata_arr = lexicon_lemmata_arr[i : i+nr_of_lemmata_to_query_atonce]\n",
    "        \n",
    "        # join set of lemmata to send them in a query all at once\n",
    "        # beware: single quotes need escaping\n",
    "        lemmata_list = \"|\".join(small_lemmata_arr).replace(\"'\", \"\\\\\\\\'\")\n",
    "        cq = create_corpus(corpus).pattern(r'[lemma=\"' + lemmata_list + r'\" & pos=\"'+pos+'\"]').search()\n",
    "        df_corpus = cq.kwic()\n",
    "        \n",
    "        # if the corpus gave results,\n",
    "        # query the lexicon for the same lemmata\n",
    "        # and compare the paradigms!\n",
    "        \n",
    "        if (len(df_corpus)>0):\n",
    "            small_lemmata_set = set(small_lemmata_arr)\n",
    "            for one_lemma in small_lemmata_set: \n",
    "                \n",
    "                # look up the known wordforms in the lexicon\n",
    "                ql = create_lexicon(lexicon).lemma(one_lemma).pos(pos).search()\n",
    "                df_known_wordforms = ql.kwic()\n",
    "                \n",
    "                # we have a lexicon paradigm to compare, do the job now\n",
    "                if (len(df_known_wordforms) != 0):\n",
    "                    \n",
    "                    # gather the lexicon wordforms in a set\n",
    "                    known_wordforms = set( df_known_wordforms['wordform'].str.lower() )\n",
    "                    \n",
    "                    # gather the corpus wordforms (of the same lemma) in a set too\n",
    "                    corpus_lemma_filter = (df_corpus['lemma 0'] == one_lemma)\n",
    "                    corpus_wordforms = set( (df_corpus[ corpus_lemma_filter ])['word 0'].str.lower() )\n",
    "                    \n",
    "                    # Now compute the differences:\n",
    "                    # gather in a set all the corpus wordforms that cannot be found in the lexicon wordforms \n",
    "                    unknown_wordforms = corpus_wordforms.difference(known_wordforms)\n",
    "\n",
    "                    # If we found some missing wordforms, add the results to the output!\n",
    "                    \n",
    "                    if (len(unknown_wordforms) !=0):                        \n",
    "                        # The index of our results will be a key consisting of lemma + part-of-speech\n",
    "                        # Part-of-speech is needed to distinguish homonyms with different grammatical categories.\n",
    "                        # Of course, we need to take glosses into account too to do a truely correct job\n",
    "                        # But we didn't do it here\n",
    "                        key = one_lemma + pos\n",
    "                        df_enriched_lexicon.at[key, 'lemma'] = one_lemma\n",
    "                        df_enriched_lexicon.at[key, 'pos'] = pos\n",
    "                        df_enriched_lexicon.at[key, 'known_wordforms'] = known_wordforms\n",
    "                        df_enriched_lexicon.at[key, 'unknown_wordforms'] = unknown_wordforms\n",
    "                \n",
    "    # return non-empty results, t.i. cases in which we found some wordforms\n",
    "    return df_enriched_lexicon[ df_enriched_lexicon['unknown_wordforms'].notnull() ]\n",
    "\n",
    "\n",
    "# Run the function!\n",
    "\n",
    "base_lexicon=\"molex\"\n",
    "corpus_to_search=\"opensonar\"\n",
    "\n",
    "df = get_missing_wordforms(base_lexicon, \"VERB\", corpus_to_search)\n",
    "\n",
    "# After such a heavy process, it's a good idea to save the results\n",
    "\n",
    "df.to_csv( \"missing_wordforms.csv\", index=False)\n",
    "\n",
    "display_df(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 9: Train a tagger with data from an annotated corpus, and do something cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T14:58:31.646967Z",
     "start_time": "2019-02-26T14:58:30.182259Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.ui.dfui import display_df\n",
    "from chaininglib.process.corpus import get_tagger\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.LexiconQuery import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "base_lexicon=\"molex\"\n",
    "\n",
    "# we have a given word, let's say: \"loop\"\n",
    "some_word = \"loop\"\n",
    "\n",
    "# get the paradigm of the lemma our word is a part of\n",
    "l = create_lexicon(base_lexicon).lemma(some_word).search()\n",
    "df_paradigm = l.kwic()\n",
    "display_df(df_paradigm)\n",
    "\n",
    "# gather some pattern including our word, out of annotated corpora\n",
    "# here: DET + ADJ + 'loop'\n",
    "\n",
    "dfs_all_corpora = []\n",
    "\n",
    "for one_corpus in get_available_corpora():\n",
    "    print('querying '+one_corpus+'...')\n",
    "    c = create_corpus(one_corpus).word(some_word).detailed_context(True).search()\n",
    "    df_corpus = c.kwic() \n",
    "    \n",
    "    # store the results\n",
    "    dfs_all_corpora.append(df_corpus)\n",
    "\n",
    "# get a tagger trained with our corpus data\n",
    "tagger = get_tagger(dfs_all_corpora)\n",
    "\n",
    "# Use the trained tagger to tag unknown sentences\n",
    "# The input must be like: tagger.tag(['today','is','a','beautiful','day'])\n",
    "\n",
    "sentence = 'Mijn buurman kijkt door de loop van zijn geweer'\n",
    "tagged_sentence = tagger.tag( sentence.split() )\n",
    "\n",
    "print(tagged_sentence)\n",
    "\n",
    "\n",
    "# Know we can lemmatize each occurence of our lemma in the new sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 10: Search in corpus and filter on metadata\n",
    "First, we request all available metadata fields of the corpus. Then, we issue a search query, and request all metadata fields for the result. Finally, we filter on metadata values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T15:07:51.051672Z",
     "start_time": "2019-02-26T15:07:50.079076Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.metadata import get_available_metadata\n",
    "from chaininglib.utils.dfops import df_filter, property_freq\n",
    "from chaininglib.ui.dfui import display_df\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "\n",
    "\n",
    "corpus_name=\"zeebrieven\"\n",
    "query=r'[lemma=\"boek\"]'\n",
    "# Request all metadata fields from corpus\n",
    "fields = get_available_metadata(corpus_name)\n",
    "# Perform query and ask all metadata\n",
    "c = create_corpus(corpus_name).pattern(query).extra_fields_doc(fields[\"document\"]).search()\n",
    "df_corpus = c.kwic()\n",
    "\n",
    "# Filter on year: > 1700\n",
    "df_filter_year = df_corpus[df_corpus[\"witnessYear_from\"].astype('int32') > 1700] \n",
    "display_df(df_filter_year, labels=\"After 1700\")\n",
    "\n",
    "# Filter on sender birth place Amsterdam\n",
    "condition = df_filter(df_corpus[\"afz_geb_plaats\"], pattern=\"Amsterdam\")\n",
    "df_filter_place = df_corpus[ condition ]\n",
    "display_df(df_filter_place, labels=\"Sender born in Amsterdam\")\n",
    "\n",
    "\n",
    "# Group by birth place\n",
    "df = property_freq(df_corpus,\"afz_loc_plaats\")\n",
    "display_df(df, labels=\"Most frequent sender locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 11: Visualizing h-dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:59:31.513866Z",
     "start_time": "2019-02-26T13:58:13.253260Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.metadata import get_available_metadata\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "corpus_to_search=\"chn\"\n",
    "\n",
    "fields = get_available_metadata(corpus_to_search)\n",
    "\n",
    "\n",
    "df_corpus1 = create_corpus(corpus_to_search).pattern(r'[lemma=\"h[aeo].*\" & word=\"[aeo].*\"]').extra_fields_doc(fields[\"document\"]).search().kwic()\n",
    "df_corpus1 = create_corpus(corpus_to_search).pattern(r'[lemma=\"h[aeo].*\" & word=\"h[aeo].*\"]').extra_fields_doc(fields[\"document\"]).search().kwic()\n",
    "\n",
    "display_df( df_corpus1)\n",
    "display_df( df_corpus2)\n",
    "\n",
    "display_df( df_corpus1.groupby([\"Region\", \"Date\"]), labels=\"h-dropping\", mode='chart')\n",
    "display_df( df_corpus2.groupby([\"Region\", \"Date\"]), labels=\"normal\", mode='chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 12: gather data from several corpora and generate a lexicon out of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T16:15:49.892955Z",
     "start_time": "2019-02-26T16:15:40.785489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying chn...\n",
      "\u001b[Fquerying opensonar...                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "\u001b[Fquerying zeebrieven...                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "\u001b[Fquerying gysseling...                                               \n",
      "\u001b[Fextracting lexicon...                                               \n",
      "Skipping corpus. extract_lexicon() expects the Pandas DataFrame input to contain at least these columns: lemma, pos and word\n",
      "Skipping corpus. extract_lexicon() expects the Pandas DataFrame input to contain at least these columns: lemma, pos and word\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>N(soort,ev,basis,zijd,stan)</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>RES(type=for)</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>RES(type=sym)</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>SPEC(symb)</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaaaaah</td>\n",
       "      <td>SPEC(deeleigen)</td>\n",
       "      <td>aaaaaaaah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aalbrecht</td>\n",
       "      <td>NOU-P(part-of-multiword=true)</td>\n",
       "      <td>aalbrecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aalst</td>\n",
       "      <td>NOU-P(number=sg)</td>\n",
       "      <td>aalst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aan</td>\n",
       "      <td>ADP(type=post)</td>\n",
       "      <td>aan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aan</td>\n",
       "      <td>ADP(type=pre)</td>\n",
       "      <td>aan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aan</td>\n",
       "      <td>VZ(fin)</td>\n",
       "      <td>aan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aan</td>\n",
       "      <td>VZ(init)</td>\n",
       "      <td>aan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aana</td>\n",
       "      <td>NOU-P(number=sg)</td>\n",
       "      <td>aana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aana</td>\n",
       "      <td>SPEC(deeleigen)</td>\n",
       "      <td>aana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aanbevelen</td>\n",
       "      <td>VRB(finiteness=ger|inf)</td>\n",
       "      <td>aanbevelen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aanblik</td>\n",
       "      <td>N(soort,ev,basis,zijd,stan)</td>\n",
       "      <td>aanblik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aanbod</td>\n",
       "      <td>N(soort,ev,basis,onz,stan)</td>\n",
       "      <td>aanbod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aanbod</td>\n",
       "      <td>NOU-C(gender=n,number=sg)</td>\n",
       "      <td>aanbod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aanbrengen</td>\n",
       "      <td>VRB(finiteness=part,tense=past)</td>\n",
       "      <td>aangebracht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aandacht</td>\n",
       "      <td>N(soort,ev,basis,zijd,stan)</td>\n",
       "      <td>aandacht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aandacht</td>\n",
       "      <td>NOU-C(gender=f|m,number=sg)</td>\n",
       "      <td>aandacht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aandachtig</td>\n",
       "      <td>AA(degree=pos,position=adv|pred)</td>\n",
       "      <td>aandachtig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aandeel</td>\n",
       "      <td>NOU-C(gender=n,number=sg)</td>\n",
       "      <td>aandeel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aandoen</td>\n",
       "      <td>VRB(finiteness=ger|inf)</td>\n",
       "      <td>aandoen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aandragen</td>\n",
       "      <td>VRB(finiteness=ger|inf)</td>\n",
       "      <td>aandragen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aandringen</td>\n",
       "      <td>VRB(finiteness=fin,mood=ind,tense=past,number=pl)</td>\n",
       "      <td>aandrongen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aanduiding</td>\n",
       "      <td>NOU-C(gender=f|m,number=sg)</td>\n",
       "      <td>aanduiding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aandurven</td>\n",
       "      <td>VRB(finiteness=fin,mood=ind,tense=past,number=sg)</td>\n",
       "      <td>aandurfde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aangaande</td>\n",
       "      <td>ADP(type=pre)</td>\n",
       "      <td>aangaande</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>aangenaam</td>\n",
       "      <td>AA(degree=pos,position=prenom,formal=infl-e)</td>\n",
       "      <td>aangename</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>aangeven</td>\n",
       "      <td>VRB(finiteness=fin,mood=ind,tense=past,number=sg)</td>\n",
       "      <td>aangaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>zuidnederlandsch</td>\n",
       "      <td>NOU-P(number=sg)</td>\n",
       "      <td>zuidnederlandsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>zuidscharwoude</td>\n",
       "      <td>NOU-P(number=sg)</td>\n",
       "      <td>zuidscharwoude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>zuinigheid</td>\n",
       "      <td>N(soort,ev,basis,zijd,stan)</td>\n",
       "      <td>zuinigheid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>zulk</td>\n",
       "      <td>PD(type=dem,position=prenom)</td>\n",
       "      <td>zulke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>zullen</td>\n",
       "      <td>VRB(finiteness=fin,mood=imp|ind,tense=pres,number=sg)</td>\n",
       "      <td>zal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>zullen</td>\n",
       "      <td>VRB(finiteness=fin,mood=ind,tense=past,number=pl)</td>\n",
       "      <td>zouden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>zullen</td>\n",
       "      <td>VRB(finiteness=fin,mood=ind,tense=past,number=sg)</td>\n",
       "      <td>zou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>zullen</td>\n",
       "      <td>VRB(finiteness=fin,mood=ind,tense=pres,number=pl)</td>\n",
       "      <td>zullen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7178</th>\n",
       "      <td>zullen</td>\n",
       "      <td>VRB(finiteness=fin,mood=ind,tense=pres,number=sg,person=2|3,formal=infl-t)</td>\n",
       "      <td>zult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7179</th>\n",
       "      <td>zullen</td>\n",
       "      <td>WW(pv,tgw,ev)</td>\n",
       "      <td>zal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>zullen</td>\n",
       "      <td>WW(pv,tgw,met-t)</td>\n",
       "      <td>zult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7181</th>\n",
       "      <td>zullen</td>\n",
       "      <td>WW(pv,tgw,mv)</td>\n",
       "      <td>zullen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7182</th>\n",
       "      <td>zullen</td>\n",
       "      <td>WW(pv,verl,ev)</td>\n",
       "      <td>zou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>zullen</td>\n",
       "      <td>WW(pv,verl,mv)</td>\n",
       "      <td>zouden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>zumba</td>\n",
       "      <td>NOU-P(number=sg)</td>\n",
       "      <td>zumba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>zutphen</td>\n",
       "      <td>NOU-P(number=sg)</td>\n",
       "      <td>zutphen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>zwaaiend</td>\n",
       "      <td>AA(degree=pos,position=prenom,formal=infl-e)</td>\n",
       "      <td>zwaaiende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>zwaar</td>\n",
       "      <td>AA(degree=pos,position=adv|pred)</td>\n",
       "      <td>zwaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7188</th>\n",
       "      <td>zwaar</td>\n",
       "      <td>AA(degree=pos,position=prenom,formal=infl-e)</td>\n",
       "      <td>zware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>zwaar</td>\n",
       "      <td>ADJ(vrij,basis,zonder)</td>\n",
       "      <td>zwaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>zwang</td>\n",
       "      <td>NOU-C(gender=f|m,number=sg)</td>\n",
       "      <td>zwang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>zwart</td>\n",
       "      <td>ADJ(prenom,basis,zonder)</td>\n",
       "      <td>zwart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>zweden</td>\n",
       "      <td>NOU-P(number=sg)</td>\n",
       "      <td>zweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>zweeds</td>\n",
       "      <td>ADJ(prenom,basis,met-e,stan)</td>\n",
       "      <td>zweedse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>zweet</td>\n",
       "      <td>NOU-C(gender=n,number=sg)</td>\n",
       "      <td>zweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>zweren</td>\n",
       "      <td>NOU-C(gender=n,number=sg)</td>\n",
       "      <td>zweren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>zwijgen</td>\n",
       "      <td>VRB(finiteness=fin,mood=ind,tense=pres,number=pl)</td>\n",
       "      <td>zwijgen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>zwoegen</td>\n",
       "      <td>N(soort,mv,basis)</td>\n",
       "      <td>zwoegen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>zwoegen</td>\n",
       "      <td>WW(inf,vrij,zonder)</td>\n",
       "      <td>zwoegen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>zwoegen</td>\n",
       "      <td>WW(pv,tgw,ev)</td>\n",
       "      <td>zwoeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lemma  \\\n",
       "0                    a   \n",
       "1                    a   \n",
       "2                    a   \n",
       "3                    a   \n",
       "4            aaaaaaaah   \n",
       "5            aalbrecht   \n",
       "6                aalst   \n",
       "7                  aan   \n",
       "8                  aan   \n",
       "9                  aan   \n",
       "10                 aan   \n",
       "11                aana   \n",
       "12                aana   \n",
       "13          aanbevelen   \n",
       "14             aanblik   \n",
       "15              aanbod   \n",
       "16              aanbod   \n",
       "17          aanbrengen   \n",
       "18            aandacht   \n",
       "19            aandacht   \n",
       "20          aandachtig   \n",
       "21             aandeel   \n",
       "22             aandoen   \n",
       "23           aandragen   \n",
       "24          aandringen   \n",
       "25          aanduiding   \n",
       "26           aandurven   \n",
       "27           aangaande   \n",
       "28           aangenaam   \n",
       "29            aangeven   \n",
       "...                ...   \n",
       "7170  zuidnederlandsch   \n",
       "7171    zuidscharwoude   \n",
       "7172        zuinigheid   \n",
       "7173              zulk   \n",
       "7174            zullen   \n",
       "7175            zullen   \n",
       "7176            zullen   \n",
       "7177            zullen   \n",
       "7178            zullen   \n",
       "7179            zullen   \n",
       "7180            zullen   \n",
       "7181            zullen   \n",
       "7182            zullen   \n",
       "7183            zullen   \n",
       "7184             zumba   \n",
       "7185           zutphen   \n",
       "7186          zwaaiend   \n",
       "7187             zwaar   \n",
       "7188             zwaar   \n",
       "7189             zwaar   \n",
       "7190             zwang   \n",
       "7191             zwart   \n",
       "7192            zweden   \n",
       "7193            zweeds   \n",
       "7194             zweet   \n",
       "7195            zweren   \n",
       "7196           zwijgen   \n",
       "7197           zwoegen   \n",
       "7198           zwoegen   \n",
       "7199           zwoegen   \n",
       "\n",
       "                                                                             pos  \\\n",
       "0                                                    N(soort,ev,basis,zijd,stan)   \n",
       "1                                                                  RES(type=for)   \n",
       "2                                                                  RES(type=sym)   \n",
       "3                                                                     SPEC(symb)   \n",
       "4                                                                SPEC(deeleigen)   \n",
       "5                                                  NOU-P(part-of-multiword=true)   \n",
       "6                                                               NOU-P(number=sg)   \n",
       "7                                                                 ADP(type=post)   \n",
       "8                                                                  ADP(type=pre)   \n",
       "9                                                                        VZ(fin)   \n",
       "10                                                                      VZ(init)   \n",
       "11                                                              NOU-P(number=sg)   \n",
       "12                                                               SPEC(deeleigen)   \n",
       "13                                                       VRB(finiteness=ger|inf)   \n",
       "14                                                   N(soort,ev,basis,zijd,stan)   \n",
       "15                                                    N(soort,ev,basis,onz,stan)   \n",
       "16                                                     NOU-C(gender=n,number=sg)   \n",
       "17                                               VRB(finiteness=part,tense=past)   \n",
       "18                                                   N(soort,ev,basis,zijd,stan)   \n",
       "19                                                   NOU-C(gender=f|m,number=sg)   \n",
       "20                                              AA(degree=pos,position=adv|pred)   \n",
       "21                                                     NOU-C(gender=n,number=sg)   \n",
       "22                                                       VRB(finiteness=ger|inf)   \n",
       "23                                                       VRB(finiteness=ger|inf)   \n",
       "24                             VRB(finiteness=fin,mood=ind,tense=past,number=pl)   \n",
       "25                                                   NOU-C(gender=f|m,number=sg)   \n",
       "26                             VRB(finiteness=fin,mood=ind,tense=past,number=sg)   \n",
       "27                                                                 ADP(type=pre)   \n",
       "28                                  AA(degree=pos,position=prenom,formal=infl-e)   \n",
       "29                             VRB(finiteness=fin,mood=ind,tense=past,number=sg)   \n",
       "...                                                                          ...   \n",
       "7170                                                            NOU-P(number=sg)   \n",
       "7171                                                            NOU-P(number=sg)   \n",
       "7172                                                 N(soort,ev,basis,zijd,stan)   \n",
       "7173                                                PD(type=dem,position=prenom)   \n",
       "7174                       VRB(finiteness=fin,mood=imp|ind,tense=pres,number=sg)   \n",
       "7175                           VRB(finiteness=fin,mood=ind,tense=past,number=pl)   \n",
       "7176                           VRB(finiteness=fin,mood=ind,tense=past,number=sg)   \n",
       "7177                           VRB(finiteness=fin,mood=ind,tense=pres,number=pl)   \n",
       "7178  VRB(finiteness=fin,mood=ind,tense=pres,number=sg,person=2|3,formal=infl-t)   \n",
       "7179                                                               WW(pv,tgw,ev)   \n",
       "7180                                                            WW(pv,tgw,met-t)   \n",
       "7181                                                               WW(pv,tgw,mv)   \n",
       "7182                                                              WW(pv,verl,ev)   \n",
       "7183                                                              WW(pv,verl,mv)   \n",
       "7184                                                            NOU-P(number=sg)   \n",
       "7185                                                            NOU-P(number=sg)   \n",
       "7186                                AA(degree=pos,position=prenom,formal=infl-e)   \n",
       "7187                                            AA(degree=pos,position=adv|pred)   \n",
       "7188                                AA(degree=pos,position=prenom,formal=infl-e)   \n",
       "7189                                                      ADJ(vrij,basis,zonder)   \n",
       "7190                                                 NOU-C(gender=f|m,number=sg)   \n",
       "7191                                                    ADJ(prenom,basis,zonder)   \n",
       "7192                                                            NOU-P(number=sg)   \n",
       "7193                                                ADJ(prenom,basis,met-e,stan)   \n",
       "7194                                                   NOU-C(gender=n,number=sg)   \n",
       "7195                                                   NOU-C(gender=n,number=sg)   \n",
       "7196                           VRB(finiteness=fin,mood=ind,tense=pres,number=pl)   \n",
       "7197                                                           N(soort,mv,basis)   \n",
       "7198                                                         WW(inf,vrij,zonder)   \n",
       "7199                                                               WW(pv,tgw,ev)   \n",
       "\n",
       "                  word  \n",
       "0                    a  \n",
       "1                    a  \n",
       "2                    a  \n",
       "3                    a  \n",
       "4            aaaaaaaah  \n",
       "5            aalbrecht  \n",
       "6                aalst  \n",
       "7                  aan  \n",
       "8                  aan  \n",
       "9                  aan  \n",
       "10                 aan  \n",
       "11                aana  \n",
       "12                aana  \n",
       "13          aanbevelen  \n",
       "14             aanblik  \n",
       "15              aanbod  \n",
       "16              aanbod  \n",
       "17         aangebracht  \n",
       "18            aandacht  \n",
       "19            aandacht  \n",
       "20          aandachtig  \n",
       "21             aandeel  \n",
       "22             aandoen  \n",
       "23           aandragen  \n",
       "24          aandrongen  \n",
       "25          aanduiding  \n",
       "26           aandurfde  \n",
       "27           aangaande  \n",
       "28           aangename  \n",
       "29              aangaf  \n",
       "...                ...  \n",
       "7170  zuidnederlandsch  \n",
       "7171    zuidscharwoude  \n",
       "7172        zuinigheid  \n",
       "7173             zulke  \n",
       "7174               zal  \n",
       "7175            zouden  \n",
       "7176               zou  \n",
       "7177            zullen  \n",
       "7178              zult  \n",
       "7179               zal  \n",
       "7180              zult  \n",
       "7181            zullen  \n",
       "7182               zou  \n",
       "7183            zouden  \n",
       "7184             zumba  \n",
       "7185           zutphen  \n",
       "7186         zwaaiende  \n",
       "7187             zwaar  \n",
       "7188             zware  \n",
       "7189             zwaar  \n",
       "7190             zwang  \n",
       "7191             zwart  \n",
       "7192            zweden  \n",
       "7193           zweedse  \n",
       "7194             zweet  \n",
       "7195            zweren  \n",
       "7196           zwijgen  \n",
       "7197           zwoegen  \n",
       "7198           zwoegen  \n",
       "7199             zwoeg  \n",
       "\n",
       "[7200 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chaininglib.ui.dfui import display_df\n",
    "from chaininglib.process.corpus import extract_lexicon\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.LexiconQuery import *\n",
    "\n",
    "dfs_all_corpora = []\n",
    "for one_corpus in get_available_corpora(exclude=[\"nederlab\"]):\n",
    "    print('querying '+one_corpus+'...')\n",
    "    c = create_corpus(one_corpus).lemma(\"woordenboek\").detailed_context(True).search()\n",
    "    df_corpus = c.kwic() \n",
    "    # store the results\n",
    "    dfs_all_corpora.append(df_corpus)\n",
    "\n",
    "# extract lexicon and show the result\n",
    "extracted_lexicon = extract_lexicon(dfs_all_corpora, posColumnName=\"pos\") # For FCS: posColumnName=universal_dependency\n",
    "display(extracted_lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 13: search treebank with some pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T15:23:24.472355Z",
     "start_time": "2019-02-26T15:23:23.333028Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.TreebankQuery import *\n",
    "\n",
    "\n",
    "print (\"search...\")\n",
    "\n",
    "tbq = create_treebank().pattern(\"xquery //node[@cat='pp' and node[@cat='ap' and node[@cat='np']]]\").search()\n",
    "#tbq = create_treebank().pattern(\"xquery //node[@cat='ap' and node[@cat='np']]\").search()\n",
    "\n",
    "print (\"get XML...\")\n",
    "\n",
    "xml = tbq.xml()\n",
    "#print(xml)\n",
    "\n",
    "print (\"get trees and their string representations...\")\n",
    "\n",
    "trees = tbq.trees()\n",
    "\n",
    "for tree in trees:\n",
    "    display(tree.toString(posTag=True))\n",
    "\n",
    "df = tbq.kwic()\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
